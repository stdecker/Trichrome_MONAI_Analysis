# Model Training File

from google.colab import drive
drive.mount('/content/drive')

import os

BASE_DIR = ""
WSI_DIR  = f"{BASE_DIR}/WSIs"
MASK_DIR = f"{BASE_DIR}/Masks_Merged"
WORK_DIR = f"{BASE_DIR}/Work/MONAI"
NORM_DIR = f"{BASE_DIR}/WSIs_norm"

os.makedirs(NORM_DIR, exist_ok=True)
print("Directories set.")


!pip install torchstain monai[tqdm] tifffile opencv-python scikit-image imagecodecs --quiet

import os, cv2, glob
import numpy as np
import tifffile as tiff
from tqdm import tqdm
import torch
import torchstain
from concurrent.futures import ThreadPoolExecutor


# --- Blended Reinhard normalization for trichrome WSIs ---
# Uses: WSI_DIR (raw), WSI_NORM_DIR (output). Adjust ALPHA to tune strength.

import os, glob, numpy as np, tifffile as tiff, cv2
from skimage.color import rgb2lab, lab2rgb
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

# Tune this: 0.3 subtle, 0.5 moderate, 0.7 stronger
ALPHA = 0.2
MAX_WORKERS = 2

def to_hwc3(img: np.ndarray) -> np.ndarray:
    """Return HxWx3 uint8 RGB (handles grayscale, channel-first, extra channels)."""
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.ndim == 3:
        # Channel-first (C,H,W) -> (H,W,C)
        if img.shape[0] in (3,4) and img.shape[-1] not in (3,4):
            img = np.transpose(img, (1,2,0))
        # Drop alpha/extra channels
        if img.shape[-1] > 3:
            img = img[..., :3]
        if img.shape[-1] == 1:
            img = np.repeat(img, 3, axis=-1)
    else:
        raise ValueError(f"Unexpected image ndim: {img.ndim}")
    if img.dtype != np.uint8:
        img = np.clip(img, 0, 255).astype(np.uint8)
    return img

def reinhard_normalize(src_rgb_uint8: np.ndarray, ref_rgb_uint8: np.ndarray) -> np.ndarray:
    """Reinhard (LAB stats matching). Both inputs uint8 RGB."""
    src = np.clip(src_rgb_uint8.astype(np.float32)/255., 0, 1)
    ref = np.clip(ref_rgb_uint8.astype(np.float32)/255., 0, 1)
    s_lab = rgb2lab(src); r_lab = rgb2lab(ref)
    s_m, s_s = s_lab.mean((0,1)), s_lab.std((0,1)) + 1e-6
    r_m, r_s = r_lab.mean((0,1)), r_lab.std((0,1)) + 1e-6
    out = (s_lab - s_m)/s_s * r_s + r_m
    out[..., 0]  = np.clip(out[..., 0],  0, 100)
    out[..., 1:] = np.clip(out[..., 1:], -128, 127)
    rgb = (np.clip(lab2rgb(out), 0, 1)*255).astype(np.uint8)
    return rgb

def blend_normalization(src_img: np.ndarray, ref_img: np.ndarray, alpha: float = 0.5) -> np.ndarray:
    """Blend original with normalized to reduce aggressiveness."""
    norm = reinhard_normalize(src_img, ref_img)
    # alpha*norm + (1-alpha)*original
    return cv2.addWeighted(norm, alpha, src_img, 1.0 - alpha, 0.0)

# Collect WSIs
raw_wsis = sorted(glob.glob(f"{WSI_DIR}/*.tif")) + sorted(glob.glob(f"{WSI_DIR}/*.tiff"))
assert raw_wsis, f"No WSIs found in {WSI_DIR}"

# Choose reference from RAW (not previously normalized)
ref_img = to_hwc3(tiff.imread(raw_wsis[1]))

def process_one(src_path: str) -> str:
    try:
        img = to_hwc3(tiff.imread(src_path))
    except Exception as e:
        raise RuntimeError(f"Failed to read {src_path}. If LZW, run: !pip install -U imagecodecs\n{e}")
    out = blend_normalization(img, ref_img, alpha=ALPHA)
    out_path = f"{NORM_DIR}/{os.path.basename(src_path)}"
    tiff.imwrite(out_path, out, compression='zlib')
    return out_path

# Run in parallel
written = []
with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
    for p in tqdm(ex.map(process_one, raw_wsis), total=len(raw_wsis), desc=f"Blended Reinhard (alpha={ALPHA})"):
        written.append(p)

# Quick sanity print
sizes = [(os.path.basename(p), os.path.getsize(p)) for p in written]
print("Wrote:", len(written), "normalized WSIs.")
print("Example sizes:", sizes[:3])


import os, glob, numpy as np, tifffile as tiff, cv2
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

TILE = 1024
OVERLAP = 256
STEP = TILE - OVERLAP

IMG_OUT = f"{WORK_DIR}/tiles/images"
MSK_OUT = f"{WORK_DIR}/tiles/masks"
os.makedirs(IMG_OUT, exist_ok=True)
os.makedirs(MSK_OUT, exist_ok=True)

# Map slide_id -> paths (support .tif / .tiff)
def base_id(p):
    return os.path.splitext(os.path.basename(p))[0]

wsis = {base_id(p): p for p in (sorted(glob.glob(f"{NORM_DIR}/*.tif")) + sorted(glob.glob(f"{NORM_DIR}/*.tiff")))}
masks= {base_id(p): p for p in (sorted(glob.glob(f"{MASK_DIR}/*.tif")) + sorted(glob.glob(f"{MASK_DIR}/*.tiff")))}

slide_ids = sorted(set(wsis.keys()) & set(masks.keys()))
print(f"Slides with both WSI+Mask: {len(slide_ids)} / WSIs:{len(wsis)} Masks:{len(masks)}")

def tile_one(sid):
    wsi_path = wsis[sid]
    msk_path = masks[sid]

    img = tiff.imread(wsi_path)
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.shape[-1] > 3:
        img = img[..., :3]

    msk = tiff.imread(msk_path)
    if msk.ndim > 2:
        msk = msk.squeeze()

    Hm, Wm = msk.shape[:2]
    Hi, Wi = img.shape[:2]
    H = min(Hm, Hi); W = min(Wm, Wi)
    if (Hi, Wi) != (Hm, Wm):
        print(f"[WARN] {sid}: WSI{(Hi,Wi)} vs MASK{(Hm,Wm)} â†’ cropping to {(H,W)}")

    wrote = 0
    for y in range(0, H, STEP):
        for x in range(0, W, STEP):
            yy = min(y+TILE, H); xx = min(x+TILE, W)
            tile_img = img[y:yy, x:xx]
            tile_msk = msk[y:yy, x:xx]

            # pad to TILE x TILE
            if tile_img.shape[0] < TILE or tile_img.shape[1] < TILE:
                pad_i = ((0, TILE - tile_img.shape[0]), (0, TILE - tile_img.shape[1]), (0, 0))
                pad_m = ((0, TILE - tile_msk.shape[0]), (0, TILE - tile_msk.shape[1]))
                tile_img = np.pad(tile_img, pad_i, mode='constant', constant_values=0)
                tile_msk = np.pad(tile_msk, pad_m, mode='constant', constant_values=0)

            out_img = f"{IMG_OUT}/{sid}_{y}_{x}.tif"
            out_msk = f"{MSK_OUT}/{sid}_{y}_{x}.tif"
            tiff.imwrite(out_img, tile_img, compression='zlib')
            tiff.imwrite(out_msk, tile_msk.astype(np.uint8), compression='zlib')
            wrote += 1
    return wrote

total = 0
with ThreadPoolExecutor(max_workers=2) as ex:
    for n in tqdm(ex.map(tile_one, slide_ids), total=len(slide_ids), desc="Tiling"):
        total += n
print("Total tiles written:", total)


# ---- Robust class count + CE weights (fast) ----
import numpy as np, tifffile as tiff, torch, glob

CLASS_NAMES = ["PT","Glom","DT","Vessel","CollectingDuct","Background","NA_Cells"]
NUM_CLASSES = len(CLASS_NAMES)
BACKGROUND_ID = CLASS_NAMES.index("Background")

from glob import glob as _glob
tile_msks = sorted(_glob(f"{MSK_OUT}/*.tif"))
assert len(tile_msks) > 0, "No mask tiles found."

# Sanitize LUT to clamp stray IDs (e.g., 255) to background
lut = np.full(256, BACKGROUND_ID, dtype=np.uint8)
lut[:NUM_CLASSES] = np.arange(NUM_CLASSES, dtype=np.uint8)

def read_sanitized(p):
    y = tiff.imread(p)
    if y.ndim > 2: y = y.squeeze()
    y = y.astype(np.uint8, copy=False)
    return lut[y]

# Fast sample ~300 tiles
step = max(1, len(tile_msks)//300)
freq = np.zeros(NUM_CLASSES, dtype=np.int64)
for p in tile_msks[::step]:
    y = read_sanitized(p)
    b = np.bincount(y.ravel(), minlength=NUM_CLASSES)
    freq += b

# Compute class weights safely (no NaN/Inf, normalized)
freq_sum = max(1, int(freq.sum()))
w = 1.0 / np.log(1.02 + (freq / freq_sum))
w = np.asarray(w, dtype=np.float32)
# guard against non-finite
if not np.all(np.isfinite(w)):
    w = np.nan_to_num(w, nan=1.0, posinf=1.0, neginf=1.0)
w = w / max(w.mean(), 1e-8)

print("Class freq:", dict(zip(CLASS_NAMES, freq.tolist())))
print("CE weights:", dict(zip(CLASS_NAMES, np.round(w, 3))))

# IMPORTANT: keep on CPU; move to GPU only when creating the loss
ce_w = torch.tensor(w, dtype=torch.float32)  # CPU tensor on purpose


# --- Drop-in replacement for Dataset + Dataloaders with label sanitization ---

import albumentations as A, cv2, torch, numpy as np, tifffile as tiff
from torch.utils.data import Dataset, DataLoader
from glob import glob

CLASS_NAMES = ["PT","Glom","DT","Vessel","CollectingDuct","Background","NA_Cells"]
NUM_CLASSES = len(CLASS_NAMES)
BACKGROUND_ID = CLASS_NAMES.index("Background")  # 5

# Build a 0..255 LUT: valid IDs map to themselves, others -> Background
LUT = np.full(256, BACKGROUND_ID, dtype=np.uint8)
LUT[:NUM_CLASSES] = np.arange(NUM_CLASSES, dtype=np.uint8)

def sanitize_labels(arr: np.ndarray) -> np.ndarray:
    if arr.ndim > 2: arr = arr.squeeze()
    arr = arr.astype(np.uint16, copy=False)        # avoid uint8 wraparound
    arr = np.where(arr < 256, arr, BACKGROUND_ID)  # clamp big values
    return LUT[arr.astype(np.uint8)]               # map through LUT

class KidneyTilesSanitized(Dataset):
    def __init__(self, imgs, msks, aug=None):
        self.imgs=imgs; self.msks=msks; self.aug=aug
    def __len__(self): return len(self.imgs)
    def __getitem__(self, i):
        x = tiff.imread(self.imgs[i])
        if x.ndim == 2: x = cv2.cvtColor(x, cv2.COLOR_GRAY2RGB)
        elif x.shape[-1] > 3: x = x[..., :3]
        y = sanitize_labels(tiff.imread(self.msks[i]))

        if self.aug:
            out = self.aug(image=x, mask=y)
            x, y = out['image'], out['mask']

        x = (x.astype(np.float32)/255.).transpose(2,0,1)
        y = y.astype(np.int64)
        return torch.from_numpy(x), torch.from_numpy(y)

# Rebuild loaders (keep your existing all_imgs/all_msks lists)
all_imgs = sorted(glob(f"{IMG_OUT}/*.tif"))
all_msks = sorted(glob(f"{MSK_OUT}/*.tif"))
split = int(0.8*len(all_imgs))
tr_imgs, va_imgs = all_imgs[:split], all_imgs[split:]
tr_msks, va_msks = all_msks[:split], all_msks[split:]

aug = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.ColorJitter(0.1,0.1,0.1,0.1, p=0.5),
], is_check_shapes=False)

BATCH = 8
tr_dl = DataLoader(KidneyTilesSanitized(tr_imgs, tr_msks, aug), batch_size=BATCH, shuffle=True,
                   num_workers=4, pin_memory=True, persistent_workers=True)
va_dl = DataLoader(KidneyTilesSanitized(va_imgs, va_msks, None), batch_size=BATCH, shuffle=False,
                   num_workers=4, pin_memory=True, persistent_workers=True)

# Quick one-batch sanity check (CPU):
import numpy as np
xx, yy = next(iter(tr_dl))
print("Batch label min/max:", int(yy.min().item()), int(yy.max().item()))
assert yy.min().item() >= 0 and yy.max().item() < NUM_CLASSES, "Sanitizer failed"


import torch, torch.nn.functional as F
from monai.networks.nets import UNet
from monai.losses import DiceLoss
from tqdm import trange, tqdm

torch.backends.cudnn.benchmark = True
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using:", device)

# --- model ---
model = UNet(
    spatial_dims=2, in_channels=3, out_channels=NUM_CLASSES,
    channels=(32,64,128,256,512), strides=(2,2,2,2)
).to(device)

# --- losses (MOVE ce_w to GPU here) ---
dice_loss = DiceLoss(include_background=True, to_onehot_y=True, softmax=True)
ce_loss   = torch.nn.CrossEntropyLoss(weight=ce_w.to(device, non_blocking=True))

# --- opt/sched/amp ---
opt   = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-4)
sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, mode="max", factor=0.5, patience=4, min_lr=1e-6, verbose=True)
scaler = torch.amp.GradScaler('cuda')

best_dice, best_path, stale = 0.0, f"{WORK_DIR}/unet_best.pt", 0
MAX_EPOCHS, PATIENCE_ES = 100, 10

for epoch in trange(1, MAX_EPOCHS+1, desc="Epochs"):
    model.train(); tloss = 0.0
    for x,y in tqdm(tr_dl, leave=False, desc=f"Train {epoch}"):
        # guards on CPU to avoid poisoning CUDA
        if y.min().item() < 0 or y.max().item() >= NUM_CLASSES:
            raise ValueError(f"Label out of range: {int(y.min())}..{int(y.max())}")
        x = x.to(device, non_blocking=True)
        y = y.to(device, non_blocking=True).long()

        with torch.amp.autocast('cuda'):
            logits = model(x)
            loss = 0.7*dice_loss(logits, y.unsqueeze(1)) + 0.3*ce_loss(logits, y)

        scaler.scale(loss).backward()
        scaler.step(opt); scaler.update()
        opt.zero_grad(set_to_none=True)
        tloss += loss.item() * x.size(0)
    tloss /= len(tr_dl.dataset)

    # --- validation ---
    model.eval(); inter=0.0; union=0.0
    with torch.no_grad():
        for x,y in va_dl:
            x = x.to(device, non_blocking=True)
            y = y.to(device, non_blocking=True).long()
            with torch.amp.autocast('cuda'):
                pred = torch.argmax(model(x), dim=1)
            po = F.one_hot(pred, NUM_CLASSES).permute(0,3,1,2).float()
            yo = F.one_hot(y,    NUM_CLASSES).permute(0,3,1,2).float()
            inter += (po*yo).sum().item()*2
            union += (po.sum()+yo.sum()).item()
    mdice = inter / (union + 1e-8)

    sched.step(mdice)
    print(f"Epoch {epoch} | train_loss={tloss:.4f} | val_mean_dice={mdice:.4f}")
    if mdice > best_dice:
        best_dice, stale = mdice, 0
        torch.save(model.state_dict(), best_path)
        print(f"** saved best: {best_path} (mDice={best_dice:.4f})")
    else:
        stale += 1
        if stale >= PATIENCE_ES:
            print("Early stop."); break


import glob, os, numpy as np, tifffile as tiff, torch
from tqdm import tqdm

TILE = 1024
OVERLAP_INFER = 256
STEP = TILE - OVERLAP_INFER
BATCH_TILES = 40
DEST_DIR = f"{WORK_DIR}/pred_wsis"
os.makedirs(DEST_DIR, exist_ok=True)

model.load_state_dict(torch.load(best_path, map_location=device))
model.eval()

def infer_wsi_fast(slide_id):
    wsi_path = f"{NORM_DIR}/{slide_id}.tif"
    mask_path= f"{MASK_DIR}/{slide_id}.tif"
    H, W = tiff.imread(mask_path).shape[:2]
    img = tiff.imread(wsi_path)
    if img.ndim == 2: img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.shape[-1] > 3: img = img[..., :3]

    prob = np.zeros((NUM_CLASSES, H, W), dtype=np.float32)
    wacc = np.zeros((H, W), dtype=np.float32)
    win = np.outer(np.hanning(TILE), np.hanning(TILE)).astype(np.float32)
    win = (win - win.min())/(win.max()-win.min()+1e-8) + 1e-3

    coords = [(y,x) for y in range(0,H,STEP) for x in range(0,W,STEP)]
    for i in tqdm(range(0, len(coords), BATCH_TILES), desc=f"Infer {slide_id}"):
        batch = coords[i:i+BATCH_TILES]
        tiles = []
        pads  = []
        for y,x in batch:
            tile = img[y:y+TILE, x:x+TILE]
            pad = ((0,0),(0,0),(0,0))
            if tile.shape[0] < TILE or tile.shape[1] < TILE:
                pad = ((0, TILE-tile.shape[0]), (0, TILE-tile.shape[1]), (0,0))
                tile = np.pad(tile, pad, mode='constant')
            tiles.append(tile.transpose(2,0,1)/255.)
            pads.append(pad)

        xt = torch.tensor(np.stack(tiles), dtype=torch.float32, device=device)
        with torch.amp.autocast('cuda'), torch.no_grad():
            prs = torch.softmax(model(xt), dim=1).detach().cpu().numpy()

        for (y,x), pr, pad in zip(batch, prs, pads):
            h = TILE - pad[0][1]; w = TILE - pad[1][1]
            winc = win[:h,:w]
            prob[:, y:y+h, x:x+w] += pr[:, :h, :w] * winc
            wacc[y:y+h, x:x+w]    += winc

    wacc[wacc==0] = 1.0
    pred = np.argmax(prob / wacc[None], axis=0).astype(np.uint8)
    tiff.imwrite(f"{DEST_DIR}/{slide_id}_pred.tif", pred, compression='zlib')

slide_ids = [os.path.splitext(os.path.basename(p))[0] for p in (sorted(glob.glob(f"{MASK_DIR}/*.tif")) + sorted(glob.glob(f"{MASK_DIR}/*.tiff")))]
for sid in slide_ids:
    infer_wsi_fast(sid)


import os, glob, numpy as np, tifffile as tiff, cv2

DEST_DIR     = f"{WORK_DIR}/pred_wsis"      # where *_pred.tif lives
WSI_NORM_DIR = f"{BASE_DIR}/WSIs_norm"      # normalized WSIs

# >>> SET THIS to your true background index <<<
BACKGROUND_ID = 5

# Your class order (for reference)
CLASS_NAMES = ["PT","Glom","DT","Vessel","CollectingDuct","Background","NA_Cells"]
NUM_CLASSES = len(CLASS_NAMES)

# Build a palette with background = black
PALETTE = np.array([
    [255,  0,  0],   # 0 PT
    [  0,255,  0],   # 1 Glom
    [  0,  0,255],   # 2 DT
    [255,255,  0],   # 3 Vessel
    [255,  0,255],   # 4 CollectingDuct
    [  0,  0,  0],   # 5 Background  (black)
    [  0,255,255],   # 6 NA_Cells
], dtype=np.uint8)
assert PALETTE.shape[0] >= NUM_CLASSES

def to_hwc3(img):
    """Return HxWx3 uint8 RGB (handles gray, channel-first, extra channels)."""
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.ndim == 3:
        # Channel-first (C,H,W) -> (H,W,C)
        if img.shape[0] in (3,4) and img.shape[-1] not in (3,4):
            img = np.transpose(img, (1,2,0))
        # Drop alpha/extra channels
        if img.shape[-1] > 3:
            img = img[..., :3]
        # If last dim is 1, expand to 3
        if img.shape[-1] == 1:
            img = np.repeat(img, 3, axis=-1)
    else:
        raise ValueError(f"Unexpected image ndim: {img.ndim}")
    if img.dtype != np.uint8:
        img = np.clip(img, 0, 255).astype(np.uint8)
    return img

def colorize_mask(label_2d):
    lab = label_2d.astype(np.int64)
    lab = np.clip(lab, 0, PALETTE.shape[0]-1)
    return PALETTE[lab]

def save_rgb_and_overlay(slide_id: str, alpha: float = 0.35, resize_interp=cv2.INTER_AREA):
    pred_path = os.path.join(DEST_DIR, f"{slide_id}_pred.tif")
    wsi_path  = os.path.join(WSI_NORM_DIR, f"{slide_id}.tif")
    if not os.path.exists(pred_path):
        print(f"[skip] Missing pred: {pred_path}"); return
    if not os.path.exists(wsi_path):
        print(f"[skip] Missing WSI: {wsi_path}"); return

    pred = tiff.imread(pred_path)
    if pred.ndim > 2: pred = pred.squeeze()
    H, W = int(pred.shape[0]), int(pred.shape[1])

    # Label sanity check
    u, c = np.unique(pred, return_counts=True)
    print(f"{slide_id} labels ->", dict(zip(u.tolist(), c.tolist())))

    # Colorized mask
    rgb = colorize_mask(pred)
    rgb_path = os.path.join(DEST_DIR, f"{slide_id}_pred_rgb.tif")
    tiff.imwrite(rgb_path, rgb, compression='zlib')

    # Load WSI and force HxWx3 RGB, then resize to pred size (W,H)
    wsi = tiff.imread(wsi_path)
    wsi = to_hwc3(wsi)
    if (wsi.shape[0], wsi.shape[1]) != (H, W):
        wsi = cv2.resize(wsi, (W, H), interpolation=resize_interp)

    # Overlay
    overlay = ((1.0 - alpha) * wsi.astype(np.float32) + alpha * rgb.astype(np.float32))
    overlay = np.clip(overlay, 0, 255).astype(np.uint8)
    overlay_path = os.path.join(DEST_DIR, f"{slide_id}_overlay.tif")
    tiff.imwrite(overlay_path, overlay, compression='zlib')

    print("Saved:", os.path.basename(rgb_path), "|", os.path.basename(overlay_path))

# Process all predicted slides
pred_files = sorted(glob.glob(os.path.join(DEST_DIR, "*_pred.tif")))
slide_ids = [os.path.basename(p).replace("_pred.tif", "") for p in pred_files]
for sid in slide_ids:
    save_rgb_and_overlay(sid, alpha=0.35)
