#Batch Processing for WSIs using Google Colab

from google.colab import drive
drive.mount('/content/drive')

import os

# INPUT WSIs (your slides)
WSI_DIR   = ""

# Normalized WSIs output (like your training step)
NORM_DIR  = ""

# Model checkpoint
CKPT_PATH = ""

# Final outputs
OUT_MASKS = ""
OUT_OVER  = ""

for d in (NORM_DIR, OUT_MASKS, OUT_OVER):
    os.makedirs(d, exist_ok=True)

print("WSI_DIR:", WSI_DIR)
print("NORM_DIR:", NORM_DIR)
print("CKPT_PATH:", CKPT_PATH)
print("OUT_MASKS:", OUT_MASKS)
print("OUT_OVER:", OUT_OVER)


!pip -q install monai-weekly[all] torch torchvision --extra-index-url https://download.pytorch.org/whl/cu121
!pip -q install tifffile imagecodecs opencv-python-headless pillow tqdm scikit-image

# --- Blended Reinhard normalization for trichrome WSIs ---
# Uses: WSI_DIR (raw), WSI_NORM_DIR (output). Adjust ALPHA to tune strength.

import os, glob, numpy as np, tifffile as tiff, cv2
from skimage.color import rgb2lab, lab2rgb
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm

# Tune this: 0.3 subtle, 0.5 moderate, 0.7 stronger
ALPHA = 0.3
MAX_WORKERS = 4

def to_hwc3(img: np.ndarray) -> np.ndarray:
    """Return HxWx3 uint8 RGB (handles grayscale, channel-first, extra channels)."""
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.ndim == 3:
        # Channel-first (C,H,W) -> (H,W,C)
        if img.shape[0] in (3,4) and img.shape[-1] not in (3,4):
            img = np.transpose(img, (1,2,0))
        # Drop alpha/extra channels
        if img.shape[-1] > 3:
            img = img[..., :3]
        if img.shape[-1] == 1:
            img = np.repeat(img, 3, axis=-1)
    else:
        raise ValueError(f"Unexpected image ndim: {img.ndim}")
    if img.dtype != np.uint8:
        img = np.clip(img, 0, 255).astype(np.uint8)
    return img

def reinhard_normalize(src_rgb_uint8: np.ndarray, ref_rgb_uint8: np.ndarray) -> np.ndarray:
    """Reinhard (LAB stats matching). Both inputs uint8 RGB."""
    src = np.clip(src_rgb_uint8.astype(np.float32)/255., 0, 1)
    ref = np.clip(ref_rgb_uint8.astype(np.float32)/255., 0, 1)
    s_lab = rgb2lab(src); r_lab = rgb2lab(ref)
    s_m, s_s = s_lab.mean((0,1)), s_lab.std((0,1)) + 1e-6
    r_m, r_s = r_lab.mean((0,1)), r_lab.std((0,1)) + 1e-6
    out = (s_lab - s_m)/s_s * r_s + r_m
    out[..., 0]  = np.clip(out[..., 0],  0, 100)
    out[..., 1:] = np.clip(out[..., 1:], -128, 127)
    rgb = (np.clip(lab2rgb(out), 0, 1)*255).astype(np.uint8)
    return rgb

def blend_normalization(src_img: np.ndarray, ref_img: np.ndarray, alpha: float = 0.5) -> np.ndarray:
    """Blend original with normalized to reduce aggressiveness."""
    norm = reinhard_normalize(src_img, ref_img)
    # alpha*norm + (1-alpha)*original
    return cv2.addWeighted(norm, alpha, src_img, 1.0 - alpha, 0.0)

# Collect WSIs
raw_wsis = sorted(glob.glob(f"{WSI_DIR}/*.tif")) + sorted(glob.glob(f"{WSI_DIR}/*.tiff"))
assert raw_wsis, f"No WSIs found in {WSI_DIR}"

# Choose reference from RAW (not previously normalized)
ref_img = to_hwc3(tiff.imread(raw_wsis[6]))

def process_one(src_path: str) -> str:
    try:
        img = to_hwc3(tiff.imread(src_path))
    except Exception as e:
        raise RuntimeError(f"Failed to read {src_path}. If LZW, run: !pip install -U imagecodecs\n{e}")
    out = blend_normalization(img, ref_img, alpha=ALPHA)
    out_path = f"{NORM_DIR}/{os.path.basename(src_path)}"
    tiff.imwrite(out_path, out, compression='zlib')
    return out_path

# Run in parallel
written = []
with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:
    for p in tqdm(ex.map(process_one, raw_wsis), total=len(raw_wsis), desc=f"Blended Reinhard (alpha={ALPHA})"):
        written.append(p)

# Quick sanity print
sizes = [(os.path.basename(p), os.path.getsize(p)) for p in written]
print("Wrote:", len(written), "normalized WSIs.")
print("Example sizes:", sizes[:3])


import torch
from monai.networks.nets import UNet

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = True

CLASS_NAMES = ["PT","Glom","DT","Vessel","CollectingDuct","Background","NA_Cells"]
NUM_CLASSES = len(CLASS_NAMES)   # 7
PT_ID, DT_ID, BG_ID = 0, 2, 5

model = UNet(
    spatial_dims=2,
    in_channels=3,
    out_channels=NUM_CLASSES,
    channels=(32,64,128,256,512),
    strides=(2,2,2,2)
).to(device)

state = torch.load(CKPT_PATH, map_location="cpu")  # plain state_dict
model.load_state_dict(state, strict=True)
model.eval()
print("Model loaded on", device)


import numpy as np, cv2, tifffile as tiff, os, glob
from tqdm import tqdm

# Tiling params (tune as needed)
TILE = 1024
OVERLAP = 256
STEP = TILE - OVERLAP
BATCH_TILES = 24  # increase if VRAM allows

PALETTE = np.array([
    [255,   0,   0],  # PT
    [  0, 255,   0],  # Glom
    [  0,   0, 255],  # DT
    [255, 255,   0],  # Vessel
    [255,   0, 255],  # CollectingDuct
    [  0,   0,   0],  # Background
    [  0, 255, 255],  # NA_Cells
], dtype=np.uint8)

def to_hwc3_uint8(img):
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.ndim == 3 and img.shape[-1] > 3:
        img = img[..., :3]
    if img.dtype != np.uint8:
        img = np.clip(img, 0, 255).astype(np.uint8)
    return img

def hann2d(h, w):
    wy = np.hanning(h); wx = np.hanning(w)
    win = np.outer(wy, wx).astype(np.float32)
    win = (win - win.min()) / (win.max() - win.min() + 1e-8)
    return (win + 1e-3)

def mask_to_rgb(mask):
    out = np.zeros((*mask.shape, 3), dtype=np.uint8)
    for cls in np.unique(mask):
        if 0 <= cls < len(PALETTE):
            out[mask == cls] = PALETTE[cls]
    return out

def overlay_rgb(base_rgb_uint8, mask_rgb_uint8, alpha=0.40):
    base = base_rgb_uint8.astype(np.float32)
    mask = mask_rgb_uint8.astype(np.float32)
    return np.clip((1-alpha)*base + alpha*mask, 0, 255).astype(np.uint8)

# lumen fill to avoid ring-like PT/DT
def _fill_holes(bin_img):
    inv = (1 - bin_img).astype(np.uint8)
    h, w = inv.shape
    mask = np.zeros((h+2, w+2), np.uint8)
    flood = inv.copy()
    cv2.floodFill(flood, mask, (0,0), 2)
    holes = (inv != flood).astype(np.uint8)
    return np.where(holes == 1, 1, bin_img).astype(np.uint8)

def fill_tubule_lumen(pred_idx):
    k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3,3))
    pt = cv2.morphologyEx((pred_idx == PT_ID).astype(np.uint8), cv2.MORPH_CLOSE, k, iterations=1)
    dt = cv2.morphologyEx((pred_idx == DT_ID).astype(np.uint8), cv2.MORPH_CLOSE, k, iterations=1)
    pt_f = _fill_holes(pt); dt_f = _fill_holes(dt)
    out = pred_idx.copy()
    out[(out == BG_ID) & (pt_f == 1)] = PT_ID
    out[(out == BG_ID) & (dt_f == 1)] = DT_ID
    return out

def infer_wsi_tiled(path, model, device):
    """Tile + stitch WSI at native resolution; return (pred_idx_uint8, overlay_rgb_uint8)."""
    img_u8 = to_hwc3_uint8(tiff.imread(path))
    H, W   = img_u8.shape[:2]

    prob = np.zeros((NUM_CLASSES, H, W), dtype=np.float32)
    wacc = np.zeros((H, W), dtype=np.float32)
    win  = hann2d(TILE, TILE)

    coords = [(y, x) for y in range(0, H, STEP) for x in range(0, W, STEP)]

    for i in tqdm(range(0, len(coords), BATCH_TILES), desc=f"Infer {os.path.basename(path)}"):
        batch = coords[i:i+BATCH_TILES]
        tiles, pads = [], []
        for (y, x) in batch:
            tile = img_u8[y:y+TILE, x:x+TILE, :]
            pad = ((0,0),(0,0),(0,0))
            if tile.shape[0] < TILE or tile.shape[1] < TILE:
                pad = ((0, TILE - tile.shape[0]), (0, TILE - tile.shape[1]), (0,0))
                tile = np.pad(tile, pad, mode='constant')
            tiles.append(tile.transpose(2,0,1).astype(np.float32)/255.0)  # C,H,W
            pads.append(pad)

        # FIX: construct from numpy, THEN move to device with non_blocking
        xt = torch.from_numpy(np.stack(tiles)).to(device, non_blocking=True)

        with torch.no_grad(), torch.autocast("cuda", dtype=torch.float16, enabled=(device.type=="cuda")):
            logits = model(xt)                       # B,C,H,W
            prs = torch.softmax(logits, dim=1).detach().cpu().numpy()

        for (y, x), pr, pad in zip(batch, prs, pads):
            h = TILE - pad[0][1]; w = TILE - pad[1][1]
            winc = win[:h, :w]
            prob[:, y:y+h, x:x+w] += pr[:, :h, :w] * winc
            wacc[y:y+h, x:x+w]    += winc

    wacc[wacc == 0] = 1.0
    pred = np.argmax(prob / wacc[None], axis=0).astype(np.uint8)
    pred = fill_tubule_lumen(pred)

    mask_rgb = mask_to_rgb(pred)
    overlay  = overlay_rgb(img_u8, mask_rgb, alpha=0.40)
    return pred, overlay


# Use the normalized WSIs produced in Cell 3
wsi_paths = sorted([p for ext in ("*.tif","*.tiff") for p in glob.glob(os.path.join(NORM_DIR, ext))])
assert len(wsi_paths) > 0, f"No WSIs found in {NORM_DIR}. Did you run the normalization cell?"

print(f"Found {len(wsi_paths)} WSIs to process.")
for p in wsi_paths:
    pred_idx, overlay = infer_wsi_tiled(p, model, device)
    base = os.path.splitext(os.path.basename(p))[0]

    mask_path = os.path.join(OUT_MASKS, f"{base}_mask_idx.tif")
    over_path = os.path.join(OUT_OVER,  f"{base}_overlay.tif")
    tiff.imwrite(mask_path, pred_idx.astype(np.uint8), compression='zlib')
    tiff.imwrite(over_path,  overlay.astype(np.uint8),   compression='zlib')
    print("Saved:", os.path.basename(mask_path), "|", os.path.basename(over_path))


import glob, os, tifffile as tiff, numpy as np

mask_files = sorted(glob.glob(os.path.join(OUT_MASKS, "*_mask_idx.tif")))
print("Masks:", len(mask_files))

for mf in mask_files[:5]:
    lab = tiff.imread(mf)
    u, c = np.unique(lab, return_counts=True)
    print(os.path.basename(mf), "â†’", dict(zip(u.tolist(), c.tolist())))
